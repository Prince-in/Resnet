{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8012937,"sourceType":"datasetVersion","datasetId":4720679}],"dockerImageVersionId":30674,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport os\nimport json\nimport numpy as np\nimport torch\nimport torchvision\nfrom torch.utils.data import random_split\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\nfrom sklearn.metrics import f1_score, accuracy_score\nfrom collections import defaultdict\nfrom time import time\nfrom tqdm import tqdm\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-02T20:02:55.552873Z","iopub.execute_input":"2024-04-02T20:02:55.553276Z","iopub.status.idle":"2024-04-02T20:03:04.891280Z","shell.execute_reply.started":"2024-04-02T20:02:55.553230Z","shell.execute_reply":"2024-04-02T20:03:04.890270Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BatchNorm(nn.Module):\n    def __init__(self,num_features,eps = 1e-5,momentum = 0.1,affine = True):\n        super(BatchNorm,self).__init__()\n        self.affine = affine\n        self.curr_mean = 0\n        self.curr_var = 0\n        self.momentum = momentum\n        self.eps = torch.tensor(eps)\n        self.num_features = num_features\n        self.gamma = nn.Parameter(torch.ones(self.num_features))\n        self.beta = nn.Parameter(torch.zeros(self.num_features))\n    def forward(self,x):\n        if self.training:\n            mean = x.mean(dim = (0,2,3),keepdim = True)\n            var = x.var(dim = (0,2,3),unbiased = True,keepdim = True)\n            with torch.no_grad():\n                self.curr_mean = (1-self.momentum)*self.curr_mean + self.momentum*mean\n                self.curr_var = (1-self.momentum)*self.curr_var + self.momentum*var\n        else:\n            mean = self.curr_mean\n            var = self.curr_var\n        x = (x-mean)/(torch.sqrt(var+self.eps))\n        if self.affine:\n            x = x*self.gamma.view(1,-1,1,1) + self.beta.view(1,-1,1,1)\n        return x\n\n    \n\nclass InstanceNorm(nn.Module):\n    def __init__(self,num_features,eps = 1e-5,momentum = 0.1,affine = True):\n        super(InstanceNorm,self).__init__()\n        self.affine = affine\n        self.eps = torch.tensor(eps)\n        self.num_features = num_features\n        self.gamma = nn.Parameter(torch.ones(self.num_features))\n        self.beta = nn.Parameter(torch.zeros(self.num_features))\n    def forward(self,x):\n        mean = x.mean(dim = (2,3),keepdim = True)\n        var = x.var(dim = (2,3),keepdim = True)\n        x = (x-mean)/torch.sqrt(var+self.eps)\n        if(self.affine):\n            x = x*self.gamma.view(1,-1,1,1) + self.beta.view(1,-1,1,1)\n        return x\n\n\n    \nclass BatchInstanceNorm(nn.Module):\n    def __init__(self,num_features,momentum = 0.1,eps = 1e-5,affine = True,rho = 0.5):\n        super(BatchInstanceNorm,self).__init__()\n        self.affine = affine\n        self.curr_mean = 0\n        self.curr_var = 0\n        self.momentum = momentum\n        self.eps = torch.tensor(eps)\n        self.num_features = num_features\n        self.gamma = nn.Parameter(torch.ones(self.num_features))\n        self.beta = nn.Parameter(torch.zeros(self.num_features))\n        self.rho = rho\n        \n    def forward(self,x):\n        if self.training:\n#             print(x.shape)\n            batch_mean = x.mean(dim = (0,2,3),keepdim = True)\n            batch_var = x.var(dim = (0,2,3),unbiased = True,keepdim = True)\n            with torch.no_grad():\n                self.curr_mean = (1-self.momentum)*self.curr_mean + self.momentum*batch_mean\n                self.curr_var = (1-self.momentum)*self.curr_var + self.momentum*batch_var\n        else:\n            batch_mean = self.curr_mean\n            batch_var = self.curr_var\n        x_batch = (x-batch_mean)/torch.sqrt(batch_var+self.eps)\n        instance_mean = x.mean(dim = (2,3),keepdim = True)\n        instance_var = x.var(dim = (2,3),keepdim = True)\n        x_instance = (x-instance_mean)/torch.sqrt(instance_var+self.eps)\n        x = self.rho*x_batch + (1 - self.rho)*x_instance\n        if self.affine:\n            x = x*self.gamma.view(1,-1,1,1) + self.beta.view(1,-1,1,1)\n        return x\n\nclass LayerNorm(nn.Module):\n    def __init__(self,num_features,eps = 1e-5,affine = True):\n        super(LayerNorm,self).__init__()\n        self.num_features = num_features\n        self.affine = affine\n        self.eps = torch.tensor(eps)\n        self.gamma = nn.Parameter(torch.ones(self.num_features))\n        self.beta = nn.Parameter(torch.zeros(self.num_features))\n    def forward(self,x):\n        mean = x.mean(dim = (1,2,3),keepdim = True)\n        var = x.var(dim = (1,2,3),keepdim = True)\n        x = (x-mean)/torch.sqrt(var+self.eps)\n        if self.affine:\n            x = x*self.gamma.view(1,-1,1,1) + self.beta.view(1,-1,1,1)\n        return x\n\nclass GroupNorm(nn.Module):\n    def __init__(self,num_features,num_groups = 4,eps = 1e-5,affine = True):\n        super(GroupNorm,self).__init__()\n        self.eps = eps\n        self.num_groups = num_groups\n        self.affine = affine\n        self.num_features = num_features\n        self.gamma = nn.Parameter(torch.ones(self.num_features))\n        self.beta = nn.Parameter(torch.zeros(self.num_features))\n    def forward(self,x):\n        N,C,H,W = x.shape\n        x = x.view(N,self.num_groups,-1)\n        mean = x.mean(dim = 2,keepdim = True)\n        var = x.var(dim = 2,keepdim = True)\n        x = (x-mean)/torch.sqrt(var+self.eps)\n        x = x.view(N,C,H,W)\n        if(self.affine):\n            x = x*self.gamma.view(1,-1,1,1) + self.beta.view(1,-1,1,1)\n        return x\n        \nclass NoNorm(nn.Module):\n    def __init__(self):\n        super(NoNorm,self).__init__()\n    def forward(self,x):\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-04-02T20:03:04.893456Z","iopub.execute_input":"2024-04-02T20:03:04.893872Z","iopub.status.idle":"2024-04-02T20:03:05.073895Z","shell.execute_reply.started":"2024-04-02T20:03:04.893844Z","shell.execute_reply":"2024-04-02T20:03:05.072276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def normalization(dim,norm_type):\n    if norm_type == 'default':\n        return nn.BatchNorm2d(dim)\n    elif norm_type == 'nn':\n        return NoNorm()\n    elif norm_type == 'bn':\n        return BatchNorm(num_features = dim)\n    elif norm_type == 'in':\n        return InstanceNorm(num_features = dim)\n    elif norm_type == 'bin':\n        return BatchInstanceNorm(num_features = dim)\n    elif norm_type == 'ln':\n        return LayerNorm(num_features = dim)\n    elif norm_type == 'gn':\n        return GroupNorm(num_features = dim)\n    ","metadata":{"execution":{"iopub.status.busy":"2024-04-02T20:03:05.075886Z","iopub.execute_input":"2024-04-02T20:03:05.076661Z","iopub.status.idle":"2024-04-02T20:03:05.095538Z","shell.execute_reply.started":"2024-04-02T20:03:05.076634Z","shell.execute_reply":"2024-04-02T20:03:05.094477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = \"cuda\"\n    print('using device: cuda')\nelse:\n    device = \"cpu\"\n    print('using device: cpu')","metadata":{"execution":{"iopub.status.busy":"2024-04-02T20:03:05.098729Z","iopub.execute_input":"2024-04-02T20:03:05.099840Z","iopub.status.idle":"2024-04-02T20:03:05.162954Z","shell.execute_reply.started":"2024-04-02T20:03:05.099803Z","shell.execute_reply":"2024-04-02T20:03:05.161725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Residual_Block(nn.Module):\n    def __init__(self,in_channels,out_channels,norm_type = \"default\",stride = 1):\n        super(Residual_Block,self).__init__()\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.norm_type = norm_type\n        self.stride = stride\n        self.conv1 = nn.Conv2d(self.in_channels,self.out_channels,kernel_size = 3,stride = stride,padding = 1,bias = False)\n        self.bn1 = normalization(out_channels,norm_type)\n        self.conv2 = nn.Conv2d(self.out_channels,self.out_channels,kernel_size = 3,stride = 1,padding = 1,bias = False)\n        self.bn2 = normalization(out_channels,norm_type)\n        self.relu = nn.ReLU()\n        self.downsample = nn.Sequential()\n        if(stride != 1 or self.in_channels!=self.out_channels):\n            self.downsample = nn.Sequential(nn.Conv2d(self.in_channels,self.out_channels,\n                                                      kernel_size = 3,stride = stride,padding = 1,bias = False),normalization(self.out_channels,norm_type))\n    def forward(self,x):\n        residual = self.downsample(x)\n        x = self.relu(self.bn1(self.conv1(x)))\n        x = self.bn2(self.conv2(x))\n        x += residual\n        o = self.relu(x)\n        return o\n        \nclass ResNet(nn.Module):\n    def __init__(self,n,r,norm_type = \"default\"):\n        super(ResNet,self).__init__()\n        self.n = n\n        self.r = r\n        self.norm_type = norm_type\n        self.in_channels = 16\n        self.conv1 = nn.Conv2d(3,16,kernel_size = 3,stride = 1,padding = 1,bias = False)\n        self.bn1 = normalization(16,norm_type)\n        self.relu = nn.ReLU()\n        self.layer1 = self.create_layer(16,self.n)\n        self.layer2 = self.create_layer(32,self.n,stride = 2)\n        self.layer3 = self.create_layer(64,self.n,stride = 2)\n        self.avg_pool = nn.AvgPool2d(kernel_size = 64)\n        self.fc = nn.Linear(64,self.r)\n            \n    def create_layer(self,channels,n,stride = 1):\n        layers = []\n        layers.append(Residual_Block(self.in_channels,channels,self.norm_type,stride))\n        self.in_channels = channels\n        for i in range(1,n):\n            layers.append(Residual_Block(self.in_channels,channels,self.norm_type))\n        return nn.Sequential(*layers)\n            \n    def forward(self,x):\n        x = self.relu(self.bn1(self.conv1(x)))\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.avg_pool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-04-02T20:03:05.165246Z","iopub.execute_input":"2024-04-02T20:03:05.165652Z","iopub.status.idle":"2024-04-02T20:03:05.186184Z","shell.execute_reply.started":"2024-04-02T20:03:05.165615Z","shell.execute_reply":"2024-04-02T20:03:05.185253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Bird_dataset():\n    def __init__(self,path,transform = None):\n        self.data = datasets.ImageFolder(root = path,transform = transform)\n    def __len__(self):\n        return len(self.data)\n    def __getitem__(self,idx):\n        return self.data[idx]\ntransform = transforms.Compose([transforms.Resize((256,256)),transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\ndef get_data(path):\n    path_train = path +'/train'\n    path_val = path + '/val'\n    path_test = path + '/test'\n    train_data = Bird_dataset(path_train,transform)\n    val_data = Bird_dataset(path_val,transform)\n    test_data = Bird_dataset(path_test,transform)\n    return train_data,val_data,test_data\ndef get_loader(train_data,val_data,test_data,batch_size = 32,num_workers = 4):\n    train_loader = DataLoader(train_data,batch_size = batch_size,shuffle = True,num_workers = num_workers)\n    val_loader = DataLoader(val_data,batch_size = batch_size,shuffle = False,num_workers = num_workers)\n    test_loader = DataLoader(test_data,batch_size = batch_size,shuffle = False,num_workers = num_workers)\n    return train_loader,val_loader,test_loader","metadata":{"execution":{"iopub.status.busy":"2024-04-02T20:03:05.187350Z","iopub.execute_input":"2024-04-02T20:03:05.188377Z","iopub.status.idle":"2024-04-02T20:03:05.200560Z","shell.execute_reply.started":"2024-04-02T20:03:05.188348Z","shell.execute_reply":"2024-04-02T20:03:05.199543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data,val_data,test_data = get_data('/kaggle/input/bird-data/Birds_25')","metadata":{"execution":{"iopub.status.busy":"2024-04-02T20:03:31.116337Z","iopub.execute_input":"2024-04-02T20:03:31.117273Z","iopub.status.idle":"2024-04-02T20:03:47.652939Z","shell.execute_reply.started":"2024-04-02T20:03:31.117234Z","shell.execute_reply":"2024-04-02T20:03:47.652141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader,val_loader,test_loader = get_loader(train_data,val_data,test_data,batch_size = 64,num_workers = 4)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T20:03:47.654840Z","iopub.execute_input":"2024-04-02T20:03:47.655416Z","iopub.status.idle":"2024-04-02T20:03:47.660085Z","shell.execute_reply.started":"2024-04-02T20:03:47.655375Z","shell.execute_reply":"2024-04-02T20:03:47.659250Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.makedirs('/kaggle/working/val')\nos.makedirs('/kaggle/working/test')\nos.makedirs('/kaggle/working/train')\nos.makedirs('/kaggle/working/model')\nos.makedirs('/kaggle/working/result')","metadata":{"execution":{"iopub.status.busy":"2024-04-02T20:03:47.661094Z","iopub.execute_input":"2024-04-02T20:03:47.661376Z","iopub.status.idle":"2024-04-02T20:03:47.672626Z","shell.execute_reply.started":"2024-04-02T20:03:47.661352Z","shell.execute_reply":"2024-04-02T20:03:47.671662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train():\n    norms = ['default','bn','in','bin','gn','nn','ln']\n    model = ResNet(n = 2, r = 25,norm_type = norms[4])\n#     print(model)\n    model = nn.DataParallel(model)\n    model = model.to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.SGD(model.parameters(),lr = 0.1,weight_decay = 1e-4,momentum = 0.9)\n    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer,50,verbose = False)\n    \n    loss_dict = defaultdict(list)\n    accuracy_dict = defaultdict(list)\n    f1_dict_micro = defaultdict(list)\n    f1_dict_macro = defaultdict(list)\n    \n    best_accuracy = -1\n    best_accuracy_epoch = -1\n    print(\"----------------------Training Starts---------------------------------\")\n    for epoch in range(50):\n        print(\"\\n--------------- epoch: \",epoch)\n        \n        loss = []\n        predictions = []\n        actuals = []\n        \n        model.train()\n        for idx,batch in enumerate(train_loader):\n            images,labels = batch\n            images = images.to(device)\n            labels = labels.to(device)\n            \n            outs = model(images)\n            \n            error = criterion(outs,labels)\n            loss.append(error.item())\n            error.backward()\n            if (idx+1)%2 == 0:\n                optimizer.step()\n                optimizer.zero_grad()\n            actuals.extend(labels.squeeze().tolist())\n            predictions.extend(torch.argmax(outs,dim = 1).squeeze().tolist())\n            \n        loss_dict[\"train\"].append(np.mean(loss))\n        accuracy_dict[\"train\"].append(round(accuracy_score(actuals,predictions)*100,2))\n        f1_dict_micro[\"train\"].append(round(f1_score(actuals,predictions,average = 'micro'),4))\n        f1_dict_macro[\"train\"].append(round(f1_score(actuals,predictions,average = 'macro'),4))\n                                      \n        scheduler.step()\n        \n        print(\"-----------------------Validation------------------------\")\n        model.eval()\n        \n        loss_val = []\n        predictions = []\n        actuals = []\n                                      \n        for idx,batch in enumerate(val_loader):\n            \n            images,labels = batch\n            images = images.to(device)\n            labels = labels.to(device)\n                                      \n            actuals.extend(labels.squeeze().tolist())\n            outs = model(images)\n            predictions.extend(torch.argmax(outs,dim = 1).squeeze().tolist())\n                                      \n            error = criterion(outs,labels)\n            loss_val.append(error.item())\n            \n        f1_dict_micro[\"val\"].append(round(f1_score(actuals,predictions,average = 'micro'),4))\n        f1_dict_macro[\"val\"].append(round(f1_score(actuals,predictions,average = 'macro'),4))\n        loss_dict[\"val\"].append(np.mean(loss_val))\n        accuracy_dict[\"val\"].append(round(accuracy_score(actuals,predictions)*100,2))\n        val_accuracy = accuracy_dict[\"val\"][-1]\n        \n        print(\"Epoch: {},Train Loss: {},Train Accuracy: {}%,Train_f1_micro: {},Train_f1_macro: {},Validation Loss: {}, Validation Accuracy: {}%,Validation_f1_micro: {}, Validation_f1_macro: {} \".format(epoch,loss_dict[\"train\"][-1],accuracy_dict[\"train\"][-1],f1_dict_micro[\"train\"][-1],f1_dict_macro[\"train\"][-1],loss_dict[\"val\"][-1],accuracy_dict[\"val\"][-1],f1_dict_micro[\"val\"][-1],f1_dict_macro[\"val\"][-1]))\n                                      \n        curr_state = {\"accuracy\":val_accuracy,\"epoch\":epoch,\"best_accuracy\":best_accuracy,\"best_accuracy_epoch\":best_accuracy_epoch}\n        \n        print(f\"epoch: {epoch}, Saving model checkpoint\")\n              \n        torch.save(model,os.path.join('/kaggle/working/model','latest_checkpoint_gn_128.pth'))\n        \n        with open(os.path.join('/kaggle/working/train','training_curr_state_gn_128.json'),'w') as outfile:\n              json.dump(curr_state,outfile)\n        \n        if val_accuracy > best_accuracy:\n            \n            print(f\"best accuracy updated = {val_accuracy} against {best_accuracy}\")\n            best_accuracy = val_accuracy\n            best_accuracy_epoch = epoch\n            state = {\"accuracy\":val_accuracy,\"epoch\":epoch,\"best_accuracy\":best_accuracy,\"best_accuracy_epoch\":best_accuracy_epoch}\n            torch.save(model,os.path.join('/kaggle/working/model','best_model_checkpoint_gn_128.pth'))\n            with open(os.path.join('/kaggle/working/train','training_best_state_gn_128.json'),'w') as outfile:\n                json.dump(state,outfile)\n        \n        with open(os.path.join('/kaggle/working/result','loss_dict_gn_128.json'),\"w\") as outfile:\n            json.dump(loss_dict,outfile)\n        with open(os.path.join('/kaggle/working/result','accuracy_dict_gn_128.json'),\"w\") as outfile:\n            json.dump(accuracy_dict,outfile)\n        with open(os.path.join('/kaggle/working/result','f1_score_micro_dict_gn_128.json'),\"w\") as outfile:\n            json.dump(f1_dict_micro,outfile)\n        with open(os.path.join('/kaggle/working/result','f1_score_macro_dict_gn_128.json'),\"w\") as outfile:\n            json.dump(f1_dict_macro,outfile)\n    return","metadata":{"execution":{"iopub.status.busy":"2024-04-02T20:05:08.996143Z","iopub.execute_input":"2024-04-02T20:05:08.996505Z","iopub.status.idle":"2024-04-02T20:05:09.021413Z","shell.execute_reply.started":"2024-04-02T20:05:08.996476Z","shell.execute_reply":"2024-04-02T20:05:09.020369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train()","metadata":{"execution":{"iopub.status.busy":"2024-04-02T20:05:18.867084Z","iopub.execute_input":"2024-04-02T20:05:18.867462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}